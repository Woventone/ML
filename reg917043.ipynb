{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the needed libraries \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file and rename it df\n",
    "df_train= pd.read_csv(\"train2.csv\", index_col=0)\n",
    "\n",
    "df_test = pd.read_csv(\"test_explanatory.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10427 entries, 0 to 10426\n",
      "Data columns (total 14 columns):\n",
      "dteday          10427 non-null object\n",
      "hr              10427 non-null int64\n",
      "holiday         10427 non-null int64\n",
      "weekday         10427 non-null int64\n",
      "workingday      10427 non-null int64\n",
      "season_t        10427 non-null object\n",
      "weather         10427 non-null object\n",
      "temperature     10427 non-null float64\n",
      "s_temp          10427 non-null float64\n",
      "humidity        10427 non-null int64\n",
      "winds           10427 non-null float64\n",
      "n_employee      10427 non-null float64\n",
      "exp_employee    10427 non-null float64\n",
      "occupancy       10427 non-null int64\n",
      "dtypes: float64(5), int64(6), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#infos on the database just imported\n",
    "df_train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6952 entries, 0 to 6951\n",
      "Data columns (total 13 columns):\n",
      "dteday          6952 non-null object\n",
      "hr              6952 non-null int64\n",
      "holiday         6952 non-null int64\n",
      "weekday         6952 non-null int64\n",
      "workingday      6952 non-null int64\n",
      "season_t        6952 non-null object\n",
      "weather         6952 non-null object\n",
      "temperature     6952 non-null float64\n",
      "s_temp          6952 non-null float64\n",
      "humidity        6952 non-null int64\n",
      "winds           6952 non-null float64\n",
      "n_employee      6952 non-null float64\n",
      "exp_employee    6952 non-null float64\n",
      "dtypes: float64(5), int64(5), object(3)\n",
      "memory usage: 760.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dteday          0\n",
       "hr              0\n",
       "holiday         0\n",
       "weekday         0\n",
       "workingday      0\n",
       "season_t        0\n",
       "weather         0\n",
       "temperature     0\n",
       "s_temp          0\n",
       "humidity        0\n",
       "winds           0\n",
       "n_employee      0\n",
       "exp_employee    0\n",
       "occupancy       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the Null Values\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.sum of       dteday     hr  holiday  weekday  workingday  season_t  weather  \\\n",
       "0      False  False    False    False       False     False    False   \n",
       "1      False  False    False    False       False     False    False   \n",
       "2      False  False    False    False       False     False    False   \n",
       "3      False  False    False    False       False     False    False   \n",
       "4      False  False    False    False       False     False    False   \n",
       "5      False  False    False    False       False     False    False   \n",
       "6      False  False    False    False       False     False    False   \n",
       "7      False  False    False    False       False     False    False   \n",
       "8      False  False    False    False       False     False    False   \n",
       "9      False  False    False    False       False     False    False   \n",
       "10     False  False    False    False       False     False    False   \n",
       "11     False  False    False    False       False     False    False   \n",
       "12     False  False    False    False       False     False    False   \n",
       "13     False  False    False    False       False     False    False   \n",
       "14     False  False    False    False       False     False    False   \n",
       "15     False  False    False    False       False     False    False   \n",
       "16     False  False    False    False       False     False    False   \n",
       "17     False  False    False    False       False     False    False   \n",
       "18     False  False    False    False       False     False    False   \n",
       "19     False  False    False    False       False     False    False   \n",
       "20     False  False    False    False       False     False    False   \n",
       "21     False  False    False    False       False     False    False   \n",
       "22     False  False    False    False       False     False    False   \n",
       "23     False  False    False    False       False     False    False   \n",
       "24     False  False    False    False       False     False    False   \n",
       "25     False  False    False    False       False     False    False   \n",
       "26     False  False    False    False       False     False    False   \n",
       "27     False  False    False    False       False     False    False   \n",
       "28     False  False    False    False       False     False    False   \n",
       "29     False  False    False    False       False     False    False   \n",
       "...      ...    ...      ...      ...         ...       ...      ...   \n",
       "6922   False  False    False    False       False     False    False   \n",
       "6923   False  False    False    False       False     False    False   \n",
       "6924   False  False    False    False       False     False    False   \n",
       "6925   False  False    False    False       False     False    False   \n",
       "6926   False  False    False    False       False     False    False   \n",
       "6927   False  False    False    False       False     False    False   \n",
       "6928   False  False    False    False       False     False    False   \n",
       "6929   False  False    False    False       False     False    False   \n",
       "6930   False  False    False    False       False     False    False   \n",
       "6931   False  False    False    False       False     False    False   \n",
       "6932   False  False    False    False       False     False    False   \n",
       "6933   False  False    False    False       False     False    False   \n",
       "6934   False  False    False    False       False     False    False   \n",
       "6935   False  False    False    False       False     False    False   \n",
       "6936   False  False    False    False       False     False    False   \n",
       "6937   False  False    False    False       False     False    False   \n",
       "6938   False  False    False    False       False     False    False   \n",
       "6939   False  False    False    False       False     False    False   \n",
       "6940   False  False    False    False       False     False    False   \n",
       "6941   False  False    False    False       False     False    False   \n",
       "6942   False  False    False    False       False     False    False   \n",
       "6943   False  False    False    False       False     False    False   \n",
       "6944   False  False    False    False       False     False    False   \n",
       "6945   False  False    False    False       False     False    False   \n",
       "6946   False  False    False    False       False     False    False   \n",
       "6947   False  False    False    False       False     False    False   \n",
       "6948   False  False    False    False       False     False    False   \n",
       "6949   False  False    False    False       False     False    False   \n",
       "6950   False  False    False    False       False     False    False   \n",
       "6951   False  False    False    False       False     False    False   \n",
       "\n",
       "      temperature  s_temp  humidity  winds  n_employee  exp_employee  \n",
       "0           False   False     False  False       False         False  \n",
       "1           False   False     False  False       False         False  \n",
       "2           False   False     False  False       False         False  \n",
       "3           False   False     False  False       False         False  \n",
       "4           False   False     False  False       False         False  \n",
       "5           False   False     False  False       False         False  \n",
       "6           False   False     False  False       False         False  \n",
       "7           False   False     False  False       False         False  \n",
       "8           False   False     False  False       False         False  \n",
       "9           False   False     False  False       False         False  \n",
       "10          False   False     False  False       False         False  \n",
       "11          False   False     False  False       False         False  \n",
       "12          False   False     False  False       False         False  \n",
       "13          False   False     False  False       False         False  \n",
       "14          False   False     False  False       False         False  \n",
       "15          False   False     False  False       False         False  \n",
       "16          False   False     False  False       False         False  \n",
       "17          False   False     False  False       False         False  \n",
       "18          False   False     False  False       False         False  \n",
       "19          False   False     False  False       False         False  \n",
       "20          False   False     False  False       False         False  \n",
       "21          False   False     False  False       False         False  \n",
       "22          False   False     False  False       False         False  \n",
       "23          False   False     False  False       False         False  \n",
       "24          False   False     False  False       False         False  \n",
       "25          False   False     False  False       False         False  \n",
       "26          False   False     False  False       False         False  \n",
       "27          False   False     False  False       False         False  \n",
       "28          False   False     False  False       False         False  \n",
       "29          False   False     False  False       False         False  \n",
       "...           ...     ...       ...    ...         ...           ...  \n",
       "6922        False   False     False  False       False         False  \n",
       "6923        False   False     False  False       False         False  \n",
       "6924        False   False     False  False       False         False  \n",
       "6925        False   False     False  False       False         False  \n",
       "6926        False   False     False  False       False         False  \n",
       "6927        False   False     False  False       False         False  \n",
       "6928        False   False     False  False       False         False  \n",
       "6929        False   False     False  False       False         False  \n",
       "6930        False   False     False  False       False         False  \n",
       "6931        False   False     False  False       False         False  \n",
       "6932        False   False     False  False       False         False  \n",
       "6933        False   False     False  False       False         False  \n",
       "6934        False   False     False  False       False         False  \n",
       "6935        False   False     False  False       False         False  \n",
       "6936        False   False     False  False       False         False  \n",
       "6937        False   False     False  False       False         False  \n",
       "6938        False   False     False  False       False         False  \n",
       "6939        False   False     False  False       False         False  \n",
       "6940        False   False     False  False       False         False  \n",
       "6941        False   False     False  False       False         False  \n",
       "6942        False   False     False  False       False         False  \n",
       "6943        False   False     False  False       False         False  \n",
       "6944        False   False     False  False       False         False  \n",
       "6945        False   False     False  False       False         False  \n",
       "6946        False   False     False  False       False         False  \n",
       "6947        False   False     False  False       False         False  \n",
       "6948        False   False     False  False       False         False  \n",
       "6949        False   False     False  False       False         False  \n",
       "6950        False   False     False  False       False         False  \n",
       "6951        False   False     False  False       False         False  \n",
       "\n",
       "[6952 rows x 13 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>season_t</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>s_temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>winds</th>\n",
       "      <th>n_employee</th>\n",
       "      <th>exp_employee</th>\n",
       "      <th>occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10427</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427</td>\n",
       "      <td>10427</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "      <td>10427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2011-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fall</td>\n",
       "      <td>Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2702</td>\n",
       "      <td>6805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.586171</td>\n",
       "      <td>0.026949</td>\n",
       "      <td>3.002302</td>\n",
       "      <td>0.680253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.414831</td>\n",
       "      <td>23.847285</td>\n",
       "      <td>62.713820</td>\n",
       "      <td>12.713916</td>\n",
       "      <td>2.336256</td>\n",
       "      <td>15.134561</td>\n",
       "      <td>191.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.920372</td>\n",
       "      <td>0.161943</td>\n",
       "      <td>2.014953</td>\n",
       "      <td>0.466401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.901815</td>\n",
       "      <td>8.603002</td>\n",
       "      <td>19.345313</td>\n",
       "      <td>8.182245</td>\n",
       "      <td>0.467820</td>\n",
       "      <td>8.806866</td>\n",
       "      <td>183.072824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.940000</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.430000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.060000</td>\n",
       "      <td>31.060000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>49.240000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.290000</td>\n",
       "      <td>976.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dteday            hr       holiday       weekday    workingday  \\\n",
       "count        10427  10427.000000  10427.000000  10427.000000  10427.000000   \n",
       "unique         731           NaN           NaN           NaN           NaN   \n",
       "top     2011-07-08           NaN           NaN           NaN           NaN   \n",
       "freq            20           NaN           NaN           NaN           NaN   \n",
       "mean           NaN     11.586171      0.026949      3.002302      0.680253   \n",
       "std            NaN      6.920372      0.161943      2.014953      0.466401   \n",
       "min            NaN      0.000000      0.000000      0.000000      0.000000   \n",
       "25%            NaN      6.000000      0.000000      1.000000      0.000000   \n",
       "50%            NaN     12.000000      0.000000      3.000000      1.000000   \n",
       "75%            NaN     18.000000      0.000000      5.000000      1.000000   \n",
       "max            NaN     23.000000      1.000000      6.000000      1.000000   \n",
       "\n",
       "       season_t weather   temperature        s_temp      humidity  \\\n",
       "count     10427   10427  10427.000000  10427.000000  10427.000000   \n",
       "unique        4       4           NaN           NaN           NaN   \n",
       "top        fall   Clear           NaN           NaN           NaN   \n",
       "freq       2702    6805           NaN           NaN           NaN   \n",
       "mean        NaN     NaN     20.414831     23.847285     62.713820   \n",
       "std         NaN     NaN      7.901815      8.603002     19.345313   \n",
       "min         NaN     NaN      0.820000      0.000000      0.000000   \n",
       "25%         NaN     NaN     13.940000     16.665000     48.000000   \n",
       "50%         NaN     NaN     20.500000     24.240000     63.000000   \n",
       "75%         NaN     NaN     27.060000     31.060000     79.000000   \n",
       "max         NaN     NaN     41.000000     49.240000    100.000000   \n",
       "\n",
       "               winds    n_employee  exp_employee     occupancy  \n",
       "count   10427.000000  10427.000000  10427.000000  10427.000000  \n",
       "unique           NaN           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN           NaN  \n",
       "mean       12.713916      2.336256     15.134561    191.480100  \n",
       "std         8.182245      0.467820      8.806866    183.072824  \n",
       "min         0.000000      1.670000      0.000000      1.000000  \n",
       "25%         7.000000      2.000000      7.430000     40.000000  \n",
       "50%        11.000000      2.330000     15.000000    145.000000  \n",
       "75%        17.000000      2.670000     22.860000    282.000000  \n",
       "max        57.000000      3.000000     30.290000    976.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic desciptive statistics\n",
    "df_train.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get dummy variables\n",
    "df_train=pd.get_dummies(df_train, columns=['season_t','weather'],drop_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.get_dummies(df_test, columns=['season_t','weather'],drop_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transforming the variable of dtday into a number to trait into the model\n",
    "month = []\n",
    "import datetime as dt\n",
    "\n",
    "date=df_train['dteday']\n",
    "a=len(date)\n",
    "for i in range(a) :\n",
    "    d = dt.datetime.strptime(date[i], \"%Y-%m-%d\")\n",
    "    month.insert(i,d.month)\n",
    "month\n",
    "month_df= pd.DataFrame(month)\n",
    "month_df.head()\n",
    "\n",
    "df_train['month'] = month\n",
    "\n",
    "\n",
    "import time\n",
    "seq = range(10427)\n",
    "time_epoch = np.array(seq)\n",
    "for i in seq:\n",
    "    time_epoch[i] = time.mktime(time.strptime(df_train.iloc[i,0], '%Y-%m-%d'))\n",
    "df2=df_train\n",
    "df2[\"dteday\"]=time_epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the variable of dtday into a number to trait into the model\n",
    "month = []\n",
    "import datetime as dt\n",
    "\n",
    "date=df_test['dteday']\n",
    "a=len(date)\n",
    "for j in range(a) :\n",
    "    d = dt.datetime.strptime(date[j], \"%Y-%m-%d\")\n",
    "    month.insert(j,d.month)\n",
    "month\n",
    "month_df= pd.DataFrame(month)\n",
    "month_df.head()\n",
    "\n",
    "df_test['month'] = month\n",
    "\n",
    "\n",
    "import time\n",
    "seq = range(6952)\n",
    "time_epoch = np.array(seq)\n",
    "for j in seq:\n",
    "    time_epoch[j] = time.mktime(time.strptime(df_test.iloc[j,0], '%Y-%m-%d'))\n",
    "df3=df_test\n",
    "df3[\"dteday\"]=time_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-165f070845b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualize the relationship between the features and the response using scatterplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'occupancy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "%matplotlib inline\n",
    "sns.pairplot(df_train, x_vars=df.columns, y_vars='occupancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can visualise the correlation using a heatmap in Seaborn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(data=df.corr().round(2), cmap='coolwarm', linewidths=.5, annot=True, annot_kws={\"size\":12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first drop --> to create X and y and remove the temperature which has high correlation with s_temp\n",
    "X=df_train\n",
    "X.drop(\"temperature\", axis = 'columns', inplace=True)\n",
    "y=X[[\"occupancy\"]]\n",
    "X.drop(\"occupancy\", axis = 'columns', inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop after the summary and p-values checking --> done initilinear regression, but it doesn't affect the random forest\n",
    "X.drop(\"n_employee\", axis = 'columns', inplace=True)\n",
    "X.drop(\"exp_employee\", axis = 'columns', inplace=True)\n",
    "X.drop(\"season_t_spring\", axis = 'columns', inplace=True)\n",
    "X.drop(\"weather_Snow\", axis = 'columns', inplace=True)\n",
    "X.drop(\"winds\", axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(\"temperature\", axis = 'columns', inplace=True)\n",
    "df_test.drop(\"n_employee\", axis = 'columns', inplace=True)\n",
    "df_test.drop(\"exp_employee\", axis = 'columns', inplace=True)\n",
    "df_test.drop(\"season_t_spring\", axis = 'columns', inplace=True)\n",
    "df_test.drop(\"weather_Snow\", axis = 'columns', inplace=True)\n",
    "df_test.drop(\"winds\", axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>s_temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>season_t_summer</th>\n",
       "      <th>season_t_winter</th>\n",
       "      <th>weather_Cloudy</th>\n",
       "      <th>weather_LightRain</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305756000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24.240</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1345327200</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.545</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1316815200</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27.275</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1352070000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.395</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1321052400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.120</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  hr  holiday  weekday  workingday  s_temp  humidity  \\\n",
       "0  1305756000   1        0        4           1  24.240        94   \n",
       "1  1345327200  18        0        0           0  29.545        78   \n",
       "2  1316815200   8        0        6           0  27.275        90   \n",
       "3  1352070000   4        0        1           1  14.395        52   \n",
       "4  1321052400   0        0        6           0  12.120        60   \n",
       "\n",
       "   season_t_summer  season_t_winter  weather_Cloudy  weather_LightRain  month  \n",
       "0                1                0               0                  0      5  \n",
       "1                0                0               1                  0      8  \n",
       "2                0                1               1                  0      9  \n",
       "3                0                1               1                  0     11  \n",
       "4                0                1               0                  0     11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>s_temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>season_t_summer</th>\n",
       "      <th>season_t_winter</th>\n",
       "      <th>weather_Cloudy</th>\n",
       "      <th>weather_LightRain</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340402400</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>34.850</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325458800</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.365</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319752800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15.150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338242400</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.605</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295478000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dteday  hr  holiday  weekday  workingday  s_temp  humidity  \\\n",
       "0  1340402400  19        0        6           0  34.850        27   \n",
       "1  1325458800  20        1        1           0  11.365        41   \n",
       "2  1319752800   2        0        5           1  15.150        66   \n",
       "3  1338242400  19        0        2           1  35.605        52   \n",
       "4  1295478000   0        0        4           1  11.365        56   \n",
       "\n",
       "   season_t_summer  season_t_winter  weather_Cloudy  weather_LightRain  month  \n",
       "0                0                0               0                  0      6  \n",
       "1                0                0               0                  0      1  \n",
       "2                0                1               0                  0     10  \n",
       "3                1                0               0                  0      5  \n",
       "4                0                0               0                  0      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can visualise the correlation using a heatmap in Seabornn after the drop\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(data=df.corr().round(2), cmap='coolwarm', linewidths=.5, annot=True, annot_kws={\"size\":12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lckwo\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dteday               0\n",
       "hr                   0\n",
       "holiday              0\n",
       "weekday              0\n",
       "workingday           0\n",
       "s_temp               0\n",
       "humidity             0\n",
       "season_t_summer      0\n",
       "season_t_winter      0\n",
       "weather_Cloudy       0\n",
       "weather_LightRain    0\n",
       "month                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    " #                                                   test_size=0.3,\n",
    "  #                                                  random_state=123)\n",
    "\n",
    "#X_test.reset_index(inplace=True)\n",
    "#X_train.reset_index(inplace=True)\n",
    "#y_test.reset_index(inplace=True)\n",
    "#y_train.reset_index(inplace=True)\n",
    "X.reset_index(inplace=True)\n",
    "y.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace =True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler(copy = True)\n",
    "X_train_scaled = scaler.fit_transform(X[[\"dteday\", \"hr\",\"s_temp\", \"humidity\", \"month\"]])\n",
    "X_train_scaled=pd.DataFrame(X_train_scaled)\n",
    "#test\n",
    "X_test_scaled = scaler.transform(df_test[[\"dteday\", \"hr\",\"s_temp\", \"humidity\", \"month\"]])\n",
    "X_test_scaled=pd.DataFrame(X_test_scaled)\n",
    "\n",
    "\n",
    "X[[\"dteday\", \"hr\",\"s_temp\", \"humidity\",\"month\"]]=X_train_scaled[[0,1,2,3,4]]\n",
    "df_test[[\"dteday\", \"hr\",\"s_temp\", \"humidity\",\"month\"]]=X_test_scaled[[0,1,2,3,4]]\n",
    "\n",
    "X.drop(\"index\", axis = 'columns', inplace=True)\n",
    "df_test.drop(\"index\", axis = 'columns', inplace=True)\n",
    "y.drop(\"index\", axis = 'columns', inplace=True)\n",
    "#y_test.drop(\"index\", axis = 'columns', inplace=True)\n",
    "\n",
    "\n",
    "X.isnull().sum()\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "import numpy as np\n",
    "\n",
    "regressor = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "                      max_features='auto', max_leaf_nodes=None,\n",
    "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                      min_samples_leaf=1, min_samples_split=2,\n",
    "                      min_weight_fraction_leaf=0.0, n_estimators=400,\n",
    "                      n_jobs=None, oob_score=False, random_state=None,\n",
    "                      verbose=0, warm_start=False)\n",
    "parameters ={} #\"n_estimators\":[2000], \"criterion\": ['mse'], \n",
    "              #\"min_samples_leaf\": [0.1,1], \"random_state\" : [123]}\n",
    "\n",
    "regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=5, n_jobs=-1, verbose=5, refit=True) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('**GRIDSEARCH RESULTS**')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    #test on hold-out\n",
    "gs.score(X_train, y_train)\n",
    "gs.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation and vsualization of the different results of cv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "MAEs = cross_val_score(estimator= regressor, X=X_train, y=y_train, scoring='neg_mean_absolute_error', cv=10)\n",
    "set(MAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test on hold-out\n",
    "from sklearn import metrics\n",
    "gs.score(X_test, y_test)\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, gs.predict(X_train))) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, gs.predict(X_train)))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, gs.predict(X_train))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, gs.predict(X_train))))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test, gs.predict(X_test))) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, gs.predict(X_test))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, gs.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lckwo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#predicting the test set results\n",
    "regressor.fit(X, y)\n",
    "y_pred = regressor.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([382.4425, 105.265 ,  11.575 , ...,  60.5075, 218.7625,  32.1075])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>384.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.5325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>547.4250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.7700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  384.4125\n",
       "1  104.5325\n",
       "2   11.4500\n",
       "3  547.4250\n",
       "4   11.7700"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.drop(0, axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and relevancy of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "#If we want to add a constant to our model\n",
    "X_train = X_train.iloc[:,:]\n",
    "est = sm.OLS(y_train,X_train)\n",
    "est_fit = est.fit()\n",
    "est_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(est_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxVar = max(est_fit.pvalues)\n",
    "maxVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to perform the graphic analysis of the errors we need to drop the const column\n",
    "X_train.drop(\"const\", axis = \"columns\", inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors distribution\n",
    "error_train=regressor.predict(X_train)-y_train.to_numpy().flatten()\n",
    "error_test=regressor.predict(X_test)-y_test.to_numpy().flatten()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(gs.predict(X_train),error_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),error_test, c=\"g\", label=\"test data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-1, xmax=50, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train_np = pd.DataFrame.to_numpy(y_train)\n",
    "y_test_np= pd.DataFrame.to_numpy(y_test)\n",
    "\n",
    "error_train=regressor.predict(X_train)-y_train_np\n",
    "error_test=regressor.predict(X_test)-y_test_np\n",
    "\n",
    "\n",
    "error_train = np.array(error_train).reshape(-1,1)\n",
    "scaled_error_train = StandardScaler(copy=False).fit(error_train).transform(error_train).flatten()\n",
    "scaled_error_test = StandardScaler(copy=False).fit(error_test).transform(error_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = sm.qqplot(scaled_error_train,line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "# We test a uniform distribution\n",
    "dist = getattr(scipy.stats, 'norm')\n",
    "    \n",
    "# We generate a sample of size  len(mr_scaled) of data distributed according to distribution dist\n",
    "# The function rvs generates a sample with distribution dist with mean loc and std scale\n",
    "test_dist = dist.rvs(0,1,size = len(scaled_error_train))\n",
    "test_dist.sort()\n",
    "\n",
    "# We create the percentiles for both distributions\n",
    "percs = np.linspace(0,100,21)\n",
    "q_b = np.percentile(scaled_error_train, percs)\n",
    "q_a = np.percentile(test_dist, percs)\n",
    "\n",
    "# and generate the QQ-plot \n",
    "plt.plot(q_a,q_b, ls=\"\", marker=\"o\")\n",
    "plt.title(\"QQ plot\")\n",
    "x = np.linspace(np.min((q_a.min(),q_b.min())), np.max((q_a.max(),q_b.max())))\n",
    "plt.plot(x,x, color=\"k\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estraction of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE YOUR PREDICTION on a CSV file named with your StudentID\n",
    "df = pd.DataFrame(y_pred, columns=[\"target\"])\n",
    "df.to_csv(\"917043.csv\",index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
